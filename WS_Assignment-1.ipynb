{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Webscraping Assignment-1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\reshma\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\reshma\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\reshma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4 pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Write a python program to display all the header tags from `wikipedia.org` and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                          headers\n",
      "0                       Main Page\n",
      "1            Welcome to Wikipedia\n",
      "2   From today's featured article\n",
      "3                Did you know ...\n",
      "4                     In the news\n",
      "5                     On this day\n",
      "6      From today's featured list\n",
      "7        Today's featured picture\n",
      "8        Other areas of Wikipedia\n",
      "9     Wikipedia's sister projects\n",
      "10            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "h=[]  #empty list to save the text scraped\n",
    "def headers():\n",
    "    url='https://en.wikipedia.org/wiki/Main_Page'\n",
    "    resp=requests.get(url)\n",
    "    print(resp)\n",
    "    soup=BeautifulSoup(resp.content)\n",
    "\n",
    "    header_tags=soup.find_all(['h1','h2','h3'])\n",
    "\n",
    "    for i in header_tags:\n",
    "      h.append(i.get_text())\n",
    "    \n",
    "\n",
    "headers()\n",
    "df=pd.DataFrame({'headers':h})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from  and make data frame https://presidentofindia.nic.in/index.php/former-presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                            Name           Term of office\n",
      "0            Dr. Rajendra Prasad   1st President of India\n",
      "1   Dr. Sarvepalli Radhakrishnan   2nd President of India\n",
      "2               Dr. Zakir Husain   3rd President of India\n",
      "3   Shri Varahagiri Venkata Giri   4th President of India\n",
      "4       Dr. Fakhruddin Ali Ahmed   5th President of India\n",
      "5      Shri Neelam Sanjiva Reddy   6th President of India\n",
      "6               Giani Zail Singh   7th President of India\n",
      "7            Shri R Venkataraman   8th President of India\n",
      "8        Dr Shankar Dayal Sharma  9th  President of India\n",
      "9           Shri K. R. Narayanan  10th President of India\n",
      "10        DR. A.P.J. Abdul Kalam  11th President of India\n",
      "11  Smt Pratibha Devisingh Patil  12th President of India\n",
      "12         Shri Pranab Mukherjee  13th President of India\n",
      "13          Shri Ram Nath Kovind  14th President of India\n"
     ]
    }
   ],
   "source": [
    "n=[] #empty list to save the text scraped\n",
    "def former_presidents():\n",
    "     url=\"https://presidentofindia.nic.in/index.php/former-presidents\"\n",
    "     resp=requests.get(url)\n",
    "     print(resp)\n",
    "     soup=BeautifulSoup(resp.content)\n",
    "     name=soup.find_all('div',class_=\"desc-sec\")\n",
    "\n",
    "     for i in name:\n",
    "         n.append(i.text)\n",
    "     \n",
    "former_presidents()\n",
    "\n",
    "df=pd.DataFrame(n)\n",
    "\n",
    "# Spliting the text  \n",
    "df=df[0].str.split('\\n',expand=True)\n",
    "\n",
    "#Droping the columns\n",
    "df.drop([0,3],axis=1,inplace=True)\n",
    "\n",
    "#Renaming the columns\n",
    "df=df.rename(columns={1:'Name',2:'Term of office'})\n",
    "\n",
    "#Sorting the Dataframe in ascending order\n",
    "df=df.sort_index(ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\\\n",
    "b)Top 10 ODI Batsmen along with the records of their team andrating.\\\n",
    "c)Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>49</td>\n",
       "      <td>112</td>\n",
       "      <td>5,839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>4,015</td>\n",
       "      <td>109</td>\n",
       "      <td>4,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>32</td>\n",
       "      <td>105</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>3,525</td>\n",
       "      <td>99</td>\n",
       "      <td>3,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England</td>\n",
       "      <td>29</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>3,166</td>\n",
       "      <td>89</td>\n",
       "      <td>3,166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4,007</td>\n",
       "      <td>68</td>\n",
       "      <td>4,007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Rating Points\n",
       "0         India      49    112  5,839\n",
       "1     Australia      36    110     36\n",
       "2      Pakistan   4,015    109  4,015\n",
       "3  South Africa      32    105     32\n",
       "4   New Zealand   3,525     99  3,525\n",
       "5       England      29     92     29\n",
       "6     Sri Lanka   3,166     89  3,166\n",
       "7    Bangladesh      38     83     38\n",
       "8   Afghanistan   4,007     68  4,007\n",
       "9   West Indies      34     55     34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def men_team_ranking():\n",
    "  \n",
    "        url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "        resp = requests.get(url)\n",
    "        print(resp)\n",
    "        soup= BeautifulSoup(resp.content)\n",
    "\n",
    "\n",
    "        Team=[]\n",
    "        Matches=[]\n",
    "        Points=[]\n",
    "        Rating=[]\n",
    "        Country = soup.find_all('span',class_=\"u-hide-phablet\")\n",
    "        for i in Country:\n",
    "            Team.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "            Team=Team[0:10]\n",
    "\n",
    "        match=soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "        matchs=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "        mtc = match + matchs\n",
    "\n",
    "        for i in mtc:\n",
    "            Matches.append(i.text)\n",
    "            Matches=Matches[0:10]\n",
    "            \n",
    "        pt=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "\n",
    "        pts= soup.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "        Point= pt + pts\n",
    "        for i in Point:\n",
    "            Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "            Points=Points[0:10]\n",
    "        rating = soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "        for i in rating:\n",
    "            Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "            Rating=Rating[0:10]\n",
    "            \n",
    "        df=pd.DataFrame({\"Country\":Team,\"Matches\":Matches,\"Rating\":Rating,\"Points\":Points})\n",
    "        return  df\n",
    "men_team_ranking()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td></td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Heinrich Klaasen</td>\n",
       "      <td>SA</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>=         ...</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking            Player_Name  \\\n",
       "0  \\n\\n\\n                            1\\n         ...             Babar Azam   \n",
       "1                                      2         ...           Shubman Gill   \n",
       "2                                      3         ...        Quinton de Kock   \n",
       "3                                      4         ...       Heinrich Klaasen   \n",
       "4                                      5         ...           David Warner   \n",
       "5                                      =         ...            Virat Kohli   \n",
       "6                                      7         ...           Harry Tector   \n",
       "7                                      8         ...           Rohit Sharma   \n",
       "8                                      9         ...  Rassie van der Dussen   \n",
       "9                                      10        ...            Imam-ul-Haq   \n",
       "\n",
       "  Team Rating  \n",
       "0         829  \n",
       "1  IND    823  \n",
       "2   SA    769  \n",
       "3   SA    756  \n",
       "4  AUS    747  \n",
       "5  IND    747  \n",
       "6  IRE    729  \n",
       "7  IND    725  \n",
       "8   SA    716  \n",
       "9  PAK    704  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "def men_batter_ranking():\n",
    "        url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "        resp = requests.get(url)\n",
    "        print(resp)\n",
    "\n",
    "        soup= BeautifulSoup(resp.text)\n",
    "\n",
    "        Position =[]\n",
    "        Player =[]\n",
    "        Country =[]\n",
    "        Rating =[]\n",
    "\n",
    "        #top player data\n",
    "        top_banner= soup.find('tr', attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "        Position.append(top_banner.find('td',class_='rankings-block__position').text)\n",
    "        Player.append(top_banner.find('div', class_=\"rankings-block__banner--name-large\").text) \n",
    "        Country.append(top_banner.find('span', class_='rankings-block__banner--nation').text)\n",
    "        Rating.append(top_banner.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "\n",
    "        # Extracting other Player Ranking\n",
    "        rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "        for row in rows[0:9]:\n",
    "            Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "            Player.append(row.find('a').text)\n",
    "            Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "            Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "            \n",
    "        # Storing data in Dataframe\n",
    "        df=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "        return df\n",
    "men_batter_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td></td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Keshav Maharaj</td>\n",
       "      <td>SA</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking     Player_Name Team  \\\n",
       "0  \\n\\n\\n                            1\\n         ...  Josh Hazlewood        \n",
       "1                                      2         ...  Mohammed Siraj  IND   \n",
       "2                                      3         ...  Keshav Maharaj   SA   \n",
       "3                                      4         ...     Rashid Khan  AFG   \n",
       "4                                      5         ...     Trent Boult   NZ   \n",
       "5                                      6         ...   Mohammad Nabi  AFG   \n",
       "6                                      7         ...      Adam Zampa  AUS   \n",
       "7                                      8         ...      Matt Henry   NZ   \n",
       "8                                      9         ...   Kuldeep Yadav  IND   \n",
       "9                                      10        ...  Shaheen Afridi  PAK   \n",
       "\n",
       "  Rating  \n",
       "0    670  \n",
       "1    668  \n",
       "2    656  \n",
       "3    654  \n",
       "4    653  \n",
       "5    641  \n",
       "6    635  \n",
       "7    634  \n",
       "8    632  \n",
       "9    625  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "def Men_bowler_ranking():\n",
    "        url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "        resp = requests.get(url)\n",
    "        print(resp)\n",
    "\n",
    "        soup= BeautifulSoup(resp.text)\n",
    "\n",
    "        Position =[]\n",
    "        Player =[]\n",
    "        Country =[]\n",
    "        Rating =[]\n",
    "\n",
    "        #top player data\n",
    "        top_banner= soup.find('tr', attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "        Position.append(top_banner.find('td',class_='rankings-block__position').text)\n",
    "        Player.append(top_banner.find('div', class_=\"rankings-block__banner--name-large\").text) \n",
    "        Country.append(top_banner.find('span', class_='rankings-block__banner--nation').text)\n",
    "        Rating.append(top_banner.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "\n",
    "        # Extracting other Player Ranking\n",
    "        rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "        for row in rows[0:9]:\n",
    "            Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "            Player.append(row.find('a').text)\n",
    "            Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "            Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "            \n",
    "        # Storing data in Dataframe\n",
    "        df=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "        return df\n",
    "Men_bowler_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "a)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\\\n",
    "b)Top 10 women’s ODI Batting players along with the records of their team and rating.\\\n",
    "c)Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>TeamT</th>\n",
       "      <th>MatchesM</th>\n",
       "      <th>PointsP</th>\n",
       "      <th>RatingR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\nAustralia\\nAUS\\n</td>\n",
       "      <td>19</td>\n",
       "      <td>3,084</td>\n",
       "      <td>\\n                            162\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nEngland\\nENG\\n</td>\n",
       "      <td>23</td>\n",
       "      <td>2,991</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n\\nSouth Africa\\nSA\\n</td>\n",
       "      <td>21</td>\n",
       "      <td>2,446</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\nIndia\\nIND\\n</td>\n",
       "      <td>18</td>\n",
       "      <td>1,745</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n\\nNew Zealand\\nNZ\\n</td>\n",
       "      <td>21</td>\n",
       "      <td>2,014</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\\n\\nWest Indies\\nWI\\n</td>\n",
       "      <td>18</td>\n",
       "      <td>1,610</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\\n\\nSri Lanka\\nSL\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>714</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\\n\\nBangladesh\\nBAN\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>816</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\\n\\nThailand\\nTHA\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>753</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n\\nPakistan\\nPAK\\n</td>\n",
       "      <td>21</td>\n",
       "      <td>1,435</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos                   TeamT MatchesM PointsP  \\\n",
       "0   1    \\n\\nAustralia\\nAUS\\n       19   3,084   \n",
       "1   2      \\n\\nEngland\\nENG\\n       23   2,991   \n",
       "2   3  \\n\\nSouth Africa\\nSA\\n       21   2,446   \n",
       "3   4        \\n\\nIndia\\nIND\\n       18   1,745   \n",
       "4   5   \\n\\nNew Zealand\\nNZ\\n       21   2,014   \n",
       "5   6   \\n\\nWest Indies\\nWI\\n       18   1,610   \n",
       "6   7     \\n\\nSri Lanka\\nSL\\n        9     714   \n",
       "7   8   \\n\\nBangladesh\\nBAN\\n       11     816   \n",
       "8   9     \\n\\nThailand\\nTHA\\n       11     753   \n",
       "9  10     \\n\\nPakistan\\nPAK\\n       21   1,435   \n",
       "\n",
       "                                             RatingR  \n",
       "0  \\n                            162\\n           ...  \n",
       "1                                                130  \n",
       "2                                                116  \n",
       "3                                                 97  \n",
       "4                                                 96  \n",
       "5                                                 89  \n",
       "6                                                 79  \n",
       "7                                                 74  \n",
       "8                                                 68  \n",
       "9                                                 68  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Top 10 ODI teams in women’s cricket along with the records for matches, points and rating\n",
    "def Women_odi_team_ranking():\n",
    "    url=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "    resp=requests.get(url)\n",
    "    soup=BeautifulSoup(resp.content)\n",
    "    table=soup.find('table',class_=\"table\")\n",
    "    headers=table.find_all(\"th\")\n",
    "    h=[]\n",
    "    for i in headers:\n",
    "        h.append(i.get_text(strip=True))\n",
    "\n",
    "    df=pd.DataFrame(columns=h)\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for i in rows[1:11]:\n",
    "        data=i.find_all('td')\n",
    "        row=[tr.text for tr in data] \n",
    "        l=len(df)\n",
    "        df.loc[l]=row\n",
    "\n",
    "    for i in df[\"TeamT\"]:\n",
    "        i=i.replace(\"\\n\",\"\")\n",
    "    return df\n",
    "Women_odi_team_ranking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td></td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking           Player_Name  \\\n",
       "0  \\n\\n\\n                            1\\n         ...  Natalie Sciver-Brunt   \n",
       "1                                      2         ...           Beth Mooney   \n",
       "2                                      3         ...   Chamari Athapaththu   \n",
       "3                                      4         ...       Laura Wolvaardt   \n",
       "4                                      5         ...       Smriti Mandhana   \n",
       "5                                      6         ...          Alyssa Healy   \n",
       "6                                      7         ...          Ellyse Perry   \n",
       "7                                      8         ...      Harmanpreet Kaur   \n",
       "8                                      9         ...           Meg Lanning   \n",
       "9                                      10        ...        Marizanne Kapp   \n",
       "\n",
       "  Team Rating  \n",
       "0         807  \n",
       "1  AUS    750  \n",
       "2   SL    736  \n",
       "3   SA    727  \n",
       "4  IND    708  \n",
       "5  AUS    698  \n",
       "6  AUS    697  \n",
       "7  IND    694  \n",
       "8  AUS    662  \n",
       "9   SA    642  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "def women_batter_ranking():\n",
    "        url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "        resp = requests.get(url)\n",
    "        print(resp)\n",
    "\n",
    "        soup= BeautifulSoup(resp.text)\n",
    "\n",
    "        Position =[]\n",
    "        Player =[]\n",
    "        Country =[]\n",
    "        Rating =[]\n",
    "\n",
    "        #top player data\n",
    "        top_banner= soup.find('tr', attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "        Position.append(top_banner.find('td',class_='rankings-block__position').text)\n",
    "        Player.append(top_banner.find('div', class_=\"rankings-block__banner--name-large\").text) \n",
    "        Country.append(top_banner.find('span', class_='rankings-block__banner--nation').text)\n",
    "        Rating.append(top_banner.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "\n",
    "        # Extracting other Player Ranking\n",
    "        rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "        for row in rows[0:9]:\n",
    "            Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "            Player.append(row.find('a').text)\n",
    "            Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "            Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "            \n",
    "        # Storing data in Dataframe\n",
    "        df=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "        return df\n",
    "women_batter_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td></td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>=         ...</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Ranking           Player_Name  \\\n",
       "0  \\n\\n\\n                            1\\n         ...        Marizanne Kapp   \n",
       "1                                      2         ...      Ashleigh Gardner   \n",
       "2                                      3         ...  Natalie Sciver-Brunt   \n",
       "3                                      4         ...       Hayley Matthews   \n",
       "4                                      5         ...           Amelia Kerr   \n",
       "5                                      6         ...         Deepti Sharma   \n",
       "6                                      7         ...          Ellyse Perry   \n",
       "7                                      8         ...         Jess Jonassen   \n",
       "8                                      =         ...         Sophie Devine   \n",
       "9                                      10        ...              Nida Dar   \n",
       "\n",
       "  Team Rating  \n",
       "0         385  \n",
       "1  AUS    377  \n",
       "2  ENG    360  \n",
       "3   WI    358  \n",
       "4   NZ    346  \n",
       "5  IND    312  \n",
       "6  AUS    282  \n",
       "7  AUS    227  \n",
       "8   NZ    227  \n",
       "9  PAK    224  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 women’s ODI all-rounder along with the records of their team and rating\n",
    "\n",
    "def women_odi_allrounder():\n",
    "        url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "        resp = requests.get(url)\n",
    "        print(resp)\n",
    "\n",
    "        soup= BeautifulSoup(resp.text)\n",
    "\n",
    "        Position =[]\n",
    "        Player =[]\n",
    "        Country =[]\n",
    "        Rating =[]\n",
    "\n",
    "        #top player data\n",
    "        top_banner= soup.find('tr', attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "        Position.append(top_banner.find('td',class_='rankings-block__position').text)\n",
    "        Player.append(top_banner.find('div', class_=\"rankings-block__banner--name-large\").text) \n",
    "        Country.append(top_banner.find('span', class_='rankings-block__banner--nation').text)\n",
    "        Rating.append(top_banner.find('div', class_=\"rankings-block__banner--rating\").text)\n",
    "\n",
    "        # Extracting other Player Ranking\n",
    "        rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "        for row in rows[0:9]:\n",
    "            Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "            Player.append(row.find('a').text)\n",
    "            Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "            Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "            \n",
    "        # Storing data in Dataframe\n",
    "        df=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "        return df\n",
    "women_odi_allrounder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5)Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame-\n",
    "i)Headline\\\n",
    "ii)Time\\\n",
    "iii)News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks making the biggest moves midday: SoFi, ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks are rallying to start the week, with th...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/29/stock-market-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Treasury yields rise as investors look to Fed ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/us-treasurys-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moscow claims the West is attempting to 'split...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G7 calls for immediate repeal of bans on Japan...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/g7-calls-for-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Israel-Hamas war is affecting the financial ou...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/israel-hamas-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A new hope for Ukraine aid in Washington</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/27/a-new-hope-for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russia's obsession with Ukraine has weakened i...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/26/russias-influe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Volvo Cars CEO strikes cautious tone on solid-...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/27/volvo-cars-ceo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Peak fossil fuel demand is coming, IEA chief B...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/27/peak-fossil-fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global demand for oil, coal and gas set to pea...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/24/demand-for-fos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>America’s first major offshore wind farm insta...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/19/americas-first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The world's largest offshore wind farm produce...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/09/the-worlds-lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vietnam is at the 'leading edge' of AI develop...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/video/2023/10/30/vietnam-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Israel-Hamas war hasn't affected Thai Airw...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/video/2023/10/23/the-isra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Southeast Asia looks to renewable power for en...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/17/southeast-asia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What Thailand's new coalition government means...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/10/what-thailands...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Southeast Asia is set to drive up demand for g...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/03/southeast-asia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Is your hotel sustainable? Not if these two th...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/is-your-hotel-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The best places — and best times — to take a s...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/25/the-best-place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Revenge travel is over — even in China, says C...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/24/revenge-travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>He visited every country in the world — withou...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/19/44-year-old-tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>These are the world's 50 best bars in 2023 — a...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/18/what-are-the-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21-year-old spent $300 to start his sticker si...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/how-sticker-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Why this financial coach tells clients to budg...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/30/why-this-finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>McDonald's HR exec: The No. 1 skill you get wo...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/29/mcdonalds-hr-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The top 10 best states for millennials—New Yor...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/29/best-states-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The No. 1 most ‘overlooked’ skill kids with hi...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cnbc.com/2023/10/29/kids-with-high...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline Time  \\\n",
       "0   Stocks making the biggest moves midday: SoFi, ...        \n",
       "1   Stocks are rallying to start the week, with th...        \n",
       "2   Treasury yields rise as investors look to Fed ...        \n",
       "3   Moscow claims the West is attempting to 'split...        \n",
       "4   G7 calls for immediate repeal of bans on Japan...        \n",
       "5   Israel-Hamas war is affecting the financial ou...        \n",
       "6            A new hope for Ukraine aid in Washington        \n",
       "7   Russia's obsession with Ukraine has weakened i...        \n",
       "8   Volvo Cars CEO strikes cautious tone on solid-...        \n",
       "9   Peak fossil fuel demand is coming, IEA chief B...        \n",
       "10  Global demand for oil, coal and gas set to pea...        \n",
       "11  America’s first major offshore wind farm insta...        \n",
       "12  The world's largest offshore wind farm produce...        \n",
       "13  Vietnam is at the 'leading edge' of AI develop...        \n",
       "14  The Israel-Hamas war hasn't affected Thai Airw...        \n",
       "15  Southeast Asia looks to renewable power for en...        \n",
       "16  What Thailand's new coalition government means...        \n",
       "17  Southeast Asia is set to drive up demand for g...        \n",
       "18  Is your hotel sustainable? Not if these two th...        \n",
       "19  The best places — and best times — to take a s...        \n",
       "20  Revenge travel is over — even in China, says C...        \n",
       "21  He visited every country in the world — withou...        \n",
       "22  These are the world's 50 best bars in 2023 — a...        \n",
       "23  21-year-old spent $300 to start his sticker si...        \n",
       "24  Why this financial coach tells clients to budg...        \n",
       "25  McDonald's HR exec: The No. 1 skill you get wo...        \n",
       "26  The top 10 best states for millennials—New Yor...        \n",
       "27  The No. 1 most ‘overlooked’ skill kids with hi...        \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/10/30/stocks-making-...  \n",
       "1   https://www.cnbc.com/2023/10/29/stock-market-t...  \n",
       "2   https://www.cnbc.com/2023/10/30/us-treasurys-i...  \n",
       "3   https://www.cnbc.com/2023/10/30/ukraine-war-li...  \n",
       "4   https://www.cnbc.com/2023/10/30/g7-calls-for-i...  \n",
       "5   https://www.cnbc.com/2023/10/28/israel-hamas-w...  \n",
       "6   https://www.cnbc.com/2023/10/27/a-new-hope-for...  \n",
       "7   https://www.cnbc.com/2023/10/26/russias-influe...  \n",
       "8   https://www.cnbc.com/2023/10/27/volvo-cars-ceo...  \n",
       "9   https://www.cnbc.com/2023/10/27/peak-fossil-fu...  \n",
       "10  https://www.cnbc.com/2023/10/24/demand-for-fos...  \n",
       "11  https://www.cnbc.com/2023/10/19/americas-first...  \n",
       "12  https://www.cnbc.com/2023/10/09/the-worlds-lar...  \n",
       "13  https://www.cnbc.com/video/2023/10/30/vietnam-...  \n",
       "14  https://www.cnbc.com/video/2023/10/23/the-isra...  \n",
       "15  https://www.cnbc.com/2023/10/17/southeast-asia...  \n",
       "16  https://www.cnbc.com/2023/10/10/what-thailands...  \n",
       "17  https://www.cnbc.com/2023/10/03/southeast-asia...  \n",
       "18  https://www.cnbc.com/2023/10/30/is-your-hotel-...  \n",
       "19  https://www.cnbc.com/2023/10/25/the-best-place...  \n",
       "20  https://www.cnbc.com/2023/10/24/revenge-travel...  \n",
       "21  https://www.cnbc.com/2023/10/19/44-year-old-tr...  \n",
       "22  https://www.cnbc.com/2023/10/18/what-are-the-5...  \n",
       "23  https://www.cnbc.com/2023/10/30/how-sticker-si...  \n",
       "24  https://www.cnbc.com/2023/10/30/why-this-finan...  \n",
       "25  https://www.cnbc.com/2023/10/29/mcdonalds-hr-e...  \n",
       "26  https://www.cnbc.com/2023/10/29/best-states-mi...  \n",
       "27  https://www.cnbc.com/2023/10/29/kids-with-high...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def news():\n",
    "        url = \"https://www.cnbc.com/world/?region=world\"\n",
    "        resp = requests.get(url)\n",
    "        soup = BeautifulSoup(resp.text)\n",
    "        articles = soup.find_all(\"div\", class_=\"Card-titleContainer\")\n",
    "\n",
    "\n",
    "        headlines = []\n",
    "        times = []\n",
    "        links = []\n",
    "\n",
    "\n",
    "        for article in articles:\n",
    "            headline_elem = article.find(\"a\")\n",
    "            time_elem = article.find(\"time\")\n",
    "            \n",
    "            if headline_elem :\n",
    "                headline = headline_elem.get_text(strip=True)\n",
    "            else:\n",
    "                headline = \"\"\n",
    "            \n",
    "            if time_elem :\n",
    "                time = time_elem.get_text(strip=True)\n",
    "            else:\n",
    "                time = \"\"\n",
    "            \n",
    "            link = article.find(\"a\")[\"href\"]\n",
    "            \n",
    "            headlines.append(headline)\n",
    "            times.append(time)\n",
    "            links.append(link)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame({\"Headline\": headlines,\"Time\": times,\"News Link\": links})\n",
    "\n",
    "        return df\n",
    "news()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame-\n",
    "i)Paper Title\\\n",
    "ii)Authors\\\n",
    "iii)Published Date\\\n",
    "iv)Paper URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "def research_papers():\n",
    "    url=input(\"Enter the URL\")\n",
    "    resp=requests.get(url)\n",
    "    print(resp)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "\n",
    "\n",
    "    titles = []\n",
    "    authors = []\n",
    "    published_dates = []\n",
    "    paper_urls = []\n",
    "\n",
    "    for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "        titles.append(i.text)\n",
    "\n",
    "    for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "        authors.append(i.text)\n",
    "    \n",
    "    for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "        published_dates.append(i.text)\n",
    "\n",
    "    for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "        if \"href\" in i.attrs:\n",
    "            paper_urls.append(i[\"href\"])\n",
    "\n",
    "    df = pd.DataFrame({\"Paper Title\": titles,\"Authors\": authors,\"Published Date\": published_dates,\"Paper URL\": paper_urls})\n",
    "\n",
    "    return df\n",
    "\n",
    "research_papers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)Write a python program to scrape mentioned details from dineout.co.in and make data frame-\\\n",
    "i)Restaurant name\\\n",
    "ii)Cuisine\\\n",
    "iii)Location\\\n",
    "iv)Ratings\\\n",
    "v)Image URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cafe Watheen</td>\n",
       "      <td>Fast Food, Chinese, North Indian, Beverages</td>\n",
       "      <td>Kaloor, North Kochi</td>\n",
       "      <td>2.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miam</td>\n",
       "      <td>North Indian, Italian, Chinese, Continental</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coral Reef</td>\n",
       "      <td>North Indian, Chinese, Continental, Kerala</td>\n",
       "      <td>Coral Isle Hotel,Kacheripadi, North Kochi</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hoy Punjab</td>\n",
       "      <td>North Indian, Chinese, Beverages</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liquid State</td>\n",
       "      <td>Finger Food</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dosa World</td>\n",
       "      <td>South Indian, Beverages</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Burgeria</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>Kaloor, North Kochi</td>\n",
       "      <td>4.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Hotspot</td>\n",
       "      <td>Arabian, North Indian, Chinese, Middle Eastern...</td>\n",
       "      <td>Kadavanthra, South Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>City View</td>\n",
       "      <td>Chinese, Kerala, North Indian</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cake Hut</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>Kaloor, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>City View Lounge</td>\n",
       "      <td>North Indian, South Indian, Continental</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>3.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coq D'or</td>\n",
       "      <td>North Indian, Fast Food</td>\n",
       "      <td>The International Hotel,MG Road, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Grill Lab</td>\n",
       "      <td>Continental, Fast Food, Burger, Desserts, Beve...</td>\n",
       "      <td>Palarivattom, East Kochi</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barbeque Nation</td>\n",
       "      <td>North Indian, Continental, Chinese, Beverages,...</td>\n",
       "      <td>Kacheripadi, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>North18</td>\n",
       "      <td>North Indian, Kerala</td>\n",
       "      <td>Coral Isle Hotel,Kacheripadi, North Kochi</td>\n",
       "      <td>4.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zaatar Arabic Restaurant</td>\n",
       "      <td>Arabian, Continental</td>\n",
       "      <td>Palarivattom, East Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cassa Luciya</td>\n",
       "      <td>Continental, Italian, Beverages</td>\n",
       "      <td>Palarivattom, East Kochi</td>\n",
       "      <td>3.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Coffee Lounge</td>\n",
       "      <td>Beverages, Desserts</td>\n",
       "      <td>Centre Square Mall,MG Road, North Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thaal Kitchen</td>\n",
       "      <td>Kerala, North Indian, Chinese, Arabian</td>\n",
       "      <td>Kakkanad, East Kochi</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>La Pino'z Pizza</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Elamkulam, South Kochi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Spirited Eleven - The Sports Bar</td>\n",
       "      <td>North Indian, Chinese, Continental, Desserts</td>\n",
       "      <td>Monsoon Empress,Palarivattom, East Kochi</td>\n",
       "      <td>3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant Name  \\\n",
       "0                       Cafe Watheen   \n",
       "1                               Miam   \n",
       "2                         Coral Reef   \n",
       "3                         Hoy Punjab   \n",
       "4                       Liquid State   \n",
       "5                         Dosa World   \n",
       "6                           Burgeria   \n",
       "7                        The Hotspot   \n",
       "8                          City View   \n",
       "9                           Cake Hut   \n",
       "10                  City View Lounge   \n",
       "11                          Coq D'or   \n",
       "12                     The Grill Lab   \n",
       "13                   Barbeque Nation   \n",
       "14                           North18   \n",
       "15          Zaatar Arabic Restaurant   \n",
       "16                      Cassa Luciya   \n",
       "17                     Coffee Lounge   \n",
       "18                     Thaal Kitchen   \n",
       "19                   La Pino'z Pizza   \n",
       "20  Spirited Eleven - The Sports Bar   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0         Fast Food, Chinese, North Indian, Beverages   \n",
       "1         North Indian, Italian, Chinese, Continental   \n",
       "2          North Indian, Chinese, Continental, Kerala   \n",
       "3                    North Indian, Chinese, Beverages   \n",
       "4                                         Finger Food   \n",
       "5                             South Indian, Beverages   \n",
       "6                                           Fast Food   \n",
       "7   Arabian, North Indian, Chinese, Middle Eastern...   \n",
       "8                       Chinese, Kerala, North Indian   \n",
       "9                                            Desserts   \n",
       "10            North Indian, South Indian, Continental   \n",
       "11                            North Indian, Fast Food   \n",
       "12  Continental, Fast Food, Burger, Desserts, Beve...   \n",
       "13  North Indian, Continental, Chinese, Beverages,...   \n",
       "14                               North Indian, Kerala   \n",
       "15                               Arabian, Continental   \n",
       "16                    Continental, Italian, Beverages   \n",
       "17                                Beverages, Desserts   \n",
       "18             Kerala, North Indian, Chinese, Arabian   \n",
       "19                                            Italian   \n",
       "20       North Indian, Chinese, Continental, Desserts   \n",
       "\n",
       "                                        Location Ratings  \\\n",
       "0                            Kaloor, North Kochi     2.2   \n",
       "1                       Kacheripadi, North Kochi     4.3   \n",
       "2      Coral Isle Hotel,Kacheripadi, North Kochi     4.4   \n",
       "3                       Kacheripadi, North Kochi     4.3   \n",
       "4                       Kacheripadi, North Kochi     3.7   \n",
       "5                       Kacheripadi, North Kochi     4.3   \n",
       "6                            Kaloor, North Kochi     4.7   \n",
       "7                       Kadavanthra, South Kochi     4.3   \n",
       "8                       Kacheripadi, North Kochi       4   \n",
       "9                            Kaloor, North Kochi     4.3   \n",
       "10                      Kacheripadi, North Kochi     3.4   \n",
       "11  The International Hotel,MG Road, North Kochi     4.3   \n",
       "12                      Palarivattom, East Kochi     3.8   \n",
       "13                      Kacheripadi, North Kochi     4.3   \n",
       "14     Coral Isle Hotel,Kacheripadi, North Kochi     4.6   \n",
       "15                      Palarivattom, East Kochi     4.3   \n",
       "16                      Palarivattom, East Kochi     3.1   \n",
       "17       Centre Square Mall,MG Road, North Kochi     4.3   \n",
       "18                          Kakkanad, East Kochi     4.4   \n",
       "19                        Elamkulam, South Kochi     4.3   \n",
       "20      Monsoon Empress,Palarivattom, East Kochi       3   \n",
       "\n",
       "                                                Image  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def res_info():\n",
    "    url=\"https://www.dineout.co.in/kochi-restaurants\"\n",
    "    resp=requests.get(url)\n",
    "    print(resp)\n",
    "    soup=BeautifulSoup(resp.content)\n",
    "\n",
    "    n=[] # Names\n",
    "    for i in soup.find_all(\"a\",class_=\"restnt-name ellipsis\"):\n",
    "        n.append(i.text)\n",
    "\n",
    "    c=[] #cuisine\n",
    "    for i in soup.find_all(\"span\",class_=\"double-line-ellipsis\"):\n",
    "        c.append(i.text)\n",
    "\n",
    "    # Remove text before \"|\"\n",
    "\n",
    "    new_c=[]\n",
    "    for i in c:\n",
    "        new_c.append(i.split('|', 1)[1].strip())\n",
    "        \n",
    "\n",
    "    l=[] #location\n",
    "    for i in soup.find_all(\"div\",class_=\"restnt-loc ellipsis\"):\n",
    "        l.append(i.text)\n",
    "\n",
    "    r=[] #ratings\n",
    "    for i in soup.find_all(\"div\",class_=\"restnt-rating\")[0:21]:\n",
    "        r.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "    img=[] #images\n",
    "    for i in soup.find_all('img',class_='no-img'):\n",
    "        img.append(i['data-src'])\n",
    "    \n",
    "\n",
    "    df=pd.DataFrame({\"Restaurant Name\":n,\"Cuisine\":new_c,\"Location\":l,\"Ratings\":r,\"Image\":img})\n",
    "   \n",
    "    return df\n",
    "\n",
    "res_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
