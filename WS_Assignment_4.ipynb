{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \\\n",
    "A)Rank \\\n",
    "B) Name \\\n",
    "C) Artist \\\n",
    "D) Upload date \\\n",
    "E) Views \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date of Upload</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.65</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.32</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.84</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.50</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.14</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.09</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.71</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.57</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.09</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.01</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.96</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.48</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.16</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.97</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.92</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.</th>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.91</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.84</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.78</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.76</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.74</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.63</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.</th>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.63</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.</th>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.60</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.</th>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.56</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.</th>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.55</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.54</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.52</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.50</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Video Name  \\\n",
       "Rank                                                    \n",
       "1.                              \"Baby Shark Dance\"[6]   \n",
       "2.                                     \"Despacito\"[9]   \n",
       "3.                         \"Johny Johny Yes Papa\"[17]   \n",
       "4.                                    \"Bath Song\"[18]   \n",
       "5.                                 \"Shape of You\"[19]   \n",
       "6.                                \"See You Again\"[22]   \n",
       "7.                            \"Wheels on the Bus\"[27]   \n",
       "8.                  \"Phonics Song with Two Words\"[28]   \n",
       "9.                                  \"Uptown Funk\"[29]   \n",
       "10.   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "11.                               \"Gangnam Style\"[31]   \n",
       "12.    \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "13.                              \"Dame Tu Cosita\"[37]   \n",
       "14.                                      \"Axel F\"[38]   \n",
       "15.                                       \"Sugar\"[39]   \n",
       "16.                              \"Counting Stars\"[40]   \n",
       "17.                                        \"Roar\"[41]   \n",
       "18.                         \"Baa Baa Black Sheep\"[42]   \n",
       "19.            \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20.                              \"Lakdi Ki Kathi\"[44]   \n",
       "21.                                       \"Sorry\"[45]   \n",
       "22.                           \"Thinking Out Loud\"[46]   \n",
       "23.           \"Humpty the train on a fruits ride\"[47]   \n",
       "24.                                  \"Dark Horse\"[48]   \n",
       "25.                                     \"Perfect\"[49]   \n",
       "26.                                  \"Let Her Go\"[50]   \n",
       "27.                                       \"Faded\"[51]   \n",
       "28.                       \"Shree Hanuman Chalisa\"[52]   \n",
       "29.                              \"Girls Like You\"[53]   \n",
       "30.                                     \"Lean On\"[54]   \n",
       "\n",
       "                                                 Artist  Views  \\\n",
       "Rank                                                             \n",
       "1.          Pinkfong Baby Shark - Kids' Songs & Stories  13.65   \n",
       "2.                                           Luis Fonsi   8.32   \n",
       "3.    LooLoo Kids - Nursery Rhymes and Children's Songs   6.84   \n",
       "4.                           Cocomelon - Nursery Rhymes   6.50   \n",
       "5.                                           Ed Sheeran   6.14   \n",
       "6.                                          Wiz Khalifa   6.09   \n",
       "7.                           Cocomelon - Nursery Rhymes   5.71   \n",
       "8.                ChuChu TV Nursery Rhymes & Kids Songs   5.57   \n",
       "9.                                          Mark Ronson   5.09   \n",
       "10.                                         Miroshka TV   5.01   \n",
       "11.                                         officialpsy   4.96   \n",
       "12.                                          Get Movies   4.57   \n",
       "13.                                       Ultra Records   4.48   \n",
       "14.                                          Crazy Frog   4.16   \n",
       "15.                                            Maroon 5   3.97   \n",
       "16.                                         OneRepublic   3.92   \n",
       "17.                                          Katy Perry   3.91   \n",
       "18.                          Cocomelon - Nursery Rhymes   3.84   \n",
       "19.                                             Shakira   3.78   \n",
       "20.                                        Jingle Toons   3.76   \n",
       "21.                                       Justin Bieber   3.74   \n",
       "22.                                          Ed Sheeran   3.69   \n",
       "23.       Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.63   \n",
       "24.                                          Katy Perry   3.63   \n",
       "25.                                          Ed Sheeran   3.60   \n",
       "26.                                           Passenger   3.56   \n",
       "27.                                         Alan Walker   3.55   \n",
       "28.                               T-Series Bhakti Sagar   3.54   \n",
       "29.                                            Maroon 5   3.52   \n",
       "30.                                Major Lazer Official   3.50   \n",
       "\n",
       "         Date of Upload  \n",
       "Rank                     \n",
       "1.        June 17, 2016  \n",
       "2.     January 12, 2017  \n",
       "3.      October 8, 2016  \n",
       "4.          May 2, 2018  \n",
       "5.     January 30, 2017  \n",
       "6.        April 6, 2015  \n",
       "7.         May 24, 2018  \n",
       "8.        March 6, 2014  \n",
       "9.    November 19, 2014  \n",
       "10.   February 27, 2018  \n",
       "11.       July 15, 2012  \n",
       "12.    January 31, 2012  \n",
       "13.       April 5, 2018  \n",
       "14.       June 16, 2009  \n",
       "15.    January 14, 2015  \n",
       "16.        May 31, 2013  \n",
       "17.   September 5, 2013  \n",
       "18.       June 25, 2018  \n",
       "19.        June 4, 2010  \n",
       "20.       June 14, 2018  \n",
       "21.    October 22, 2015  \n",
       "22.     October 7, 2014  \n",
       "23.    January 26, 2018  \n",
       "24.   February 20, 2014  \n",
       "25.    November 9, 2017  \n",
       "26.       July 25, 2012  \n",
       "27.    December 3, 2015  \n",
       "28.        May 10, 2011  \n",
       "29.        May 31, 2018  \n",
       "30.      March 22, 2015  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the web driver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "# Scraping the table\n",
    "row_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td\")[:180]\n",
    "\n",
    "data=[]\n",
    "for i in row_tags:\n",
    "    data.append(i.text.strip())\n",
    "\n",
    "# Rank of Video   \n",
    "for i in range(0,len(data),6):\n",
    "    rank.append(data[i])\n",
    "\n",
    "# Name of the video\n",
    "for i in range(1,len(data),6):\n",
    "     name.append(data[i])\n",
    "\n",
    "# Name of the Youtuber\n",
    "for i in range(2,len(data),6):\n",
    "     artist.append(data[i])\n",
    "\n",
    "# Views on the video\n",
    "for i in range(3,len(data),6):\n",
    "     views.append(data[i])\n",
    "\n",
    "# Upload date of the video\n",
    "for i in range(4,len(data),6):\n",
    "     upload_date.append(data[i])\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# DataFrame     \n",
    "df=pd.DataFrame({\"Rank\":rank,\"Video Name\":name,\"Artist\":artist,\"Views\":views,\"Date of Upload\":upload_date})\n",
    "df.set_index(\"Rank\",inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \\\n",
    "A) Series \\\n",
    "B) Place \\\n",
    "C) Date \\\n",
    "D) Time \\\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached end of the page\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tour</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Kingsmead,</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>12 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>The Wanderers Stadium,</td>\n",
       "      <td>14 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>19 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Boland Park,</td>\n",
       "      <td>21 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>SuperSport Park,</td>\n",
       "      <td>26 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>3 JANUARY, 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>11 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>14 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>17 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>25 JANUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>2 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>15 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Tour  \\\n",
       "0      AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "1      AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "2      AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "3   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "4   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "5   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "6   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "7   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "8   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "9   INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "10  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "11   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "12   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "13   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "14       ENGLAND TOUR OF INDIA 2023-24   \n",
       "15       ENGLAND TOUR OF INDIA 2023-24   \n",
       "16       ENGLAND TOUR OF INDIA 2023-24   \n",
       "17       ENGLAND TOUR OF INDIA 2023-24   \n",
       "18       ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                             Location               Date  \\\n",
       "0                          Barsapara Cricket Stadium,  28 NOVEMBER, 2023   \n",
       "1   Shaheed Veer Narayan Singh International Crick...   1 DECEMBER, 2023   \n",
       "2                              M Chinnaswamy Stadium,   3 DECEMBER, 2023   \n",
       "3                                          Kingsmead,  10 DECEMBER, 2023   \n",
       "4                                   St George's Park,  12 DECEMBER, 2023   \n",
       "5                              The Wanderers Stadium,  14 DECEMBER, 2023   \n",
       "6                                        Johannesburg  17 DECEMBER, 2023   \n",
       "7                                   St George's Park,  19 DECEMBER, 2023   \n",
       "8                                        Boland Park,  21 DECEMBER, 2023   \n",
       "9                                    SuperSport Park,  26 DECEMBER, 2023   \n",
       "10                                          Newlands,    3 JANUARY, 2024   \n",
       "11      Punjab Cricket Association IS Bindra Stadium,   11 JANUARY, 2024   \n",
       "12                            Holkar Cricket Stadium,   14 JANUARY, 2024   \n",
       "13                             M Chinnaswamy Stadium,   17 JANUARY, 2024   \n",
       "14                Rajiv Gandhi International Stadium,   25 JANUARY, 2024   \n",
       "15  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,   2 FEBRUARY, 2024   \n",
       "16            Saurashtra Cricket Association Stadium,  15 FEBRUARY, 2024   \n",
       "17                JSCA International Stadium Complex,  23 FEBRUARY, 2024   \n",
       "18      Himachal Pradesh Cricket Association Stadium,      7 MARCH, 2024   \n",
       "\n",
       "           Time  \n",
       "0   7:00 PM IST  \n",
       "1   7:00 PM IST  \n",
       "2   7:00 PM IST  \n",
       "3   9:30 PM IST  \n",
       "4   9:30 PM IST  \n",
       "5   9:30 PM IST  \n",
       "6   2:00 PM IST  \n",
       "7   2:00 PM IST  \n",
       "8   2:00 PM IST  \n",
       "9   1:30 PM IST  \n",
       "10  1:30 PM IST  \n",
       "11  7:00 PM IST  \n",
       "12  7:00 PM IST  \n",
       "13  7:00 PM IST  \n",
       "14  9:30 AM IST  \n",
       "15  9:30 AM IST  \n",
       "16  9:30 AM IST  \n",
       "17  9:30 AM IST  \n",
       "18  9:30 AM IST  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "\n",
    "# from homepage to india's international fixtures webpage\n",
    "\n",
    "WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH,\"//div[@class='imw-tabs international-tabs']/a[2]\"))).click()\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/section/div/div/div/div/div/div[2]/div[1]/div[2]/div/div[1]/div/div[1]\"))).click()\n",
    "WebDriverWait(driver,3).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/section/div/div/div/div/div/div[2]/div[1]/div[2]/div/div[1]/div/div[2]/div[11]\"))).click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Trying to display all the web element before scraping\n",
    "try:\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollBy(0,1200);\")\n",
    "        time.sleep(2)\n",
    "        WebDriverWait(driver,3).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/section/div/div/div/div/div/div[2]/div[2]/div[2]/div/button\"))).click()\n",
    "        \n",
    "except TimeoutException:\n",
    "    print(\"Reached end of the page\")       \n",
    "\n",
    "# Scraping the data\n",
    "tour=[]\n",
    "place=[]\n",
    "date=[]\n",
    "match_time=[]\n",
    "\n",
    "# Scraping web elements for tour name, venue, date and timing of the matchday\n",
    "tour_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "place_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span[1]')\n",
    "date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "\n",
    "for i in tour_tags:\n",
    "    tour.append(i.text)\n",
    "for i in place_tags:\n",
    "    place.append(i.text)\n",
    "for i in date_tags:\n",
    "    date.append(i.text)\n",
    "for i in time_tags:\n",
    "    match_time.append(i.text)   \n",
    "\n",
    "driver.close()\n",
    "\n",
    "#Dataframe\n",
    "df=pd.DataFrame({'Tour':tour,'Location':place,'Date':date,'Time':match_time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: \\\n",
    "A) Rank \\\n",
    "B) State \\\n",
    "C) GSDP(18-19)- at current prices \\\n",
    "D) GSDP(19-20)- at current prices \\\n",
    "E) Share(18-19) \\\n",
    "F) GDP($ billion)  \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19) at Current prices</th>\n",
       "      <th>GSDP(19-20) at Current prices</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($ Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) at Current prices  \\\n",
       "0     1                Maharashtra                     2,632,792   \n",
       "1     2                 Tamil Nadu                     1,630,208   \n",
       "2     3              Uttar Pradesh                     1,584,764   \n",
       "3     4                    Gujarat                     1,502,899   \n",
       "4     5                  Karnataka                     1,493,127   \n",
       "5     6                West Bengal                     1,089,898   \n",
       "6     7                  Rajasthan                       942,586   \n",
       "7     8             Andhra Pradesh                       862,957   \n",
       "8     9                  Telangana                       861,031   \n",
       "9    10             Madhya Pradesh                       809,592   \n",
       "10   11                     Kerala                       781,653   \n",
       "11   12                      Delhi                       774,870   \n",
       "12   13                    Haryana                       734,163   \n",
       "13   14                      Bihar                       530,363   \n",
       "14   15                     Punjab                       526,376   \n",
       "15   16                     Odisha                       487,805   \n",
       "16   17                      Assam                       315,881   \n",
       "17   18               Chhattisgarh                       304,063   \n",
       "18   19                  Jharkhand                       297,204   \n",
       "19   20                Uttarakhand                       245,895   \n",
       "20   21            Jammu & Kashmir                       155,956   \n",
       "21   22           Himachal Pradesh                       153,845   \n",
       "22   23                        Goa                        73,170   \n",
       "23   24                    Tripura                        49,845   \n",
       "24   25                 Chandigarh                        42,114   \n",
       "25   26                 Puducherry                        34,433   \n",
       "26   27                  Meghalaya                        33,481   \n",
       "27   28                     Sikkim                        28,723   \n",
       "28   29                    Manipur                        27,870   \n",
       "29   30                   Nagaland                        27,283   \n",
       "30   31          Arunachal Pradesh                        24,603   \n",
       "31   32                    Mizoram                        22,287   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP(19-20) at Current prices   Share GDP($ Billion)  \n",
       "0                              -  13.94%        399.921  \n",
       "1                      1,845,853   8.63%        247.629  \n",
       "2                      1,687,818   8.39%        240.726  \n",
       "3                              -   7.96%        228.290  \n",
       "4                      1,631,977   7.91%        226.806  \n",
       "5                      1,253,832   5.77%        165.556  \n",
       "6                      1,020,989   4.99%        143.179  \n",
       "7                        972,782   4.57%        131.083  \n",
       "8                        969,604   4.56%        130.791  \n",
       "9                        906,672   4.29%        122.977  \n",
       "10                             -   4.14%        118.733  \n",
       "11                       856,112   4.10%        117.703  \n",
       "12                       831,610   3.89%        111.519  \n",
       "13                       611,804   2.81%         80.562  \n",
       "14                       574,760   2.79%         79.957  \n",
       "15                       521,275   2.58%         74.098  \n",
       "16                             -   1.67%         47.982  \n",
       "17                       329,180   1.61%         46.187  \n",
       "18                       328,598   1.57%         45.145  \n",
       "19                             -   1.30%         37.351  \n",
       "20                             -   0.83%         23.690  \n",
       "21                       165,472   0.81%         23.369  \n",
       "22                        80,449   0.39%         11.115  \n",
       "23                        55,984   0.26%          7.571  \n",
       "24                             -   0.22%          6.397  \n",
       "25                        38,253   0.18%          5.230  \n",
       "26                        36,572   0.18%          5.086  \n",
       "27                        32,496   0.15%          4.363  \n",
       "28                        31,790   0.15%          4.233  \n",
       "29                             -   0.14%          4.144  \n",
       "30                             -   0.13%          3.737  \n",
       "31                        26,503   0.12%          3.385  \n",
       "32                             -       -              -  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://www.statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Getting to GDP of indian states page\n",
    "\n",
    "# 1.Economy drown-down list\n",
    "WebDriverWait(driver,3).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\"))).click()\n",
    "\n",
    "# 2.Selecting India\n",
    "WebDriverWait(driver,2).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\"))).click()\n",
    "\n",
    "# 3. Selecting link to GDP of Indian states\n",
    "try:\n",
    "    WebDriverWait(driver,2).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\"))).click()\n",
    "except :\n",
    "    driver.get('https://www.statisticstimes.com/economy/india/indian-states-gdp.php')   \n",
    "    \n",
    "\n",
    "# Scraping Data\n",
    "rank=[]\n",
    "state_name=[]\n",
    "gsdp_18_19=[]\n",
    "gsdp_19_20=[]\n",
    "share_per=[]\n",
    "gdp=[]\n",
    "\n",
    "# Ranking\n",
    "rank_tags=driver.find_elements(By.CLASS_NAME,'data1')\n",
    "for i in rank_tags[:33]:\n",
    "    rank.append(i.text)\n",
    "\n",
    "# State Names\n",
    "state_tags=driver.find_elements(By.CLASS_NAME,'name')\n",
    "for i in state_tags[:33]:\n",
    "    state_name.append(i.text)\n",
    "\n",
    "# Gross State Domestic Product for year 2018-19 \n",
    "gsdp_18_19_tags=driver.find_elements(By.XPATH,'//tr[@role=\"row\"]/td[4]')\n",
    "for i in gsdp_18_19_tags[:33]:\n",
    "    gsdp_18_19.append(i.text)\n",
    "\n",
    "# Gross State Domestic Product for year 2018-19 \n",
    "gsdp_19_20_tags=driver.find_elements(By.XPATH,'//tr[@role=\"row\"]/td[3]')\n",
    "for i in gsdp_19_20_tags[:33]:\n",
    "    gsdp_19_20.append(i.text)\n",
    "\n",
    "# Share percentage\n",
    "share_per_TAGS=driver.find_elements(By.XPATH,'//tr[@role=\"row\"]/td[5]')\n",
    "for i in share_per_TAGS[:33]:\n",
    "    share_per.append(i.text)\n",
    "\n",
    "# Gross Domenstic Product in Billion dollars unit\n",
    "gdp_tags=driver.find_elements(By.XPATH,'//tr[@role=\"row\"]/td[6]')\n",
    "for i in gdp_tags[:33]:\n",
    "    gdp.append(i.text)\n",
    "\n",
    "driver.close()    \n",
    "\n",
    "# Dataframe\n",
    "df=pd.DataFrame({'Rank':rank,'State':state_name,'GSDP(18-19) at Current prices':gsdp_18_19,'GSDP(19-20) at Current prices':gsdp_19_20,\"Share\":share_per,'GDP($ Billion)':gdp})\n",
    "df    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \\\n",
    "A) Repository title \\\n",
    "B) Repository description \\\n",
    "C) Contributors count \\\n",
    "D) Language used \\\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multipleWindow3dScene</td>\n",
       "      <td>A quick example of how one can \"synchronize\" a...</td>\n",
       "      <td>2</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rags</td>\n",
       "      <td>Build ChatGPT over your data, all with natural...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roadster</td>\n",
       "      <td>2008-2012 Roadster Development and Diagnostic ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awesome-Black-Friday-Cyber-Monday</td>\n",
       "      <td>Awesome deals on Black Friday: Apps, SaaS, Boo...</td>\n",
       "      <td>567</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>live</td>\n",
       "      <td>✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clash-nyanpasu</td>\n",
       "      <td>Clash Nyanpasu!</td>\n",
       "      <td>26</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPTs</td>\n",
       "      <td>leaked prompts of GPTs</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hot-tips</td>\n",
       "      <td>The code behind my hot tips</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fooocus</td>\n",
       "      <td>Focus on prompting and generating</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>app-ideas</td>\n",
       "      <td>A Collection of application ideas which can be...</td>\n",
       "      <td>68</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>starrocks</td>\n",
       "      <td>StarRocks, a Linux Foundation project, is a ne...</td>\n",
       "      <td>293</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>botlib</td>\n",
       "      <td>C Telegram bot framework</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GitHub-Chinese-Top-Charts</td>\n",
       "      <td>🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1Panel</td>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。</td>\n",
       "      <td>38</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chatgpt_system_prompt</td>\n",
       "      <td>store all agent's system prompt</td>\n",
       "      <td>3</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>generative-models</td>\n",
       "      <td>Generative Models by Stability AI</td>\n",
       "      <td>15</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Reactive-Resume</td>\n",
       "      <td>A one-of-a-kind resume builder that keeps your...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AI-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, AI for All!</td>\n",
       "      <td>33</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>awesome-cpp</td>\n",
       "      <td>A curated list of awesome C++ (or C) framework...</td>\n",
       "      <td>381</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Black-Friday-Deals</td>\n",
       "      <td>Black Friday Deals for macOS / iOS Software &amp; ...</td>\n",
       "      <td>259</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spring-boot</td>\n",
       "      <td>Spring Boot</td>\n",
       "      <td>1,039</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>windmill</td>\n",
       "      <td>Open-source developer platform to turn scripts...</td>\n",
       "      <td>57</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Network-segmentation-cheat-sheet</td>\n",
       "      <td>Best practices for segmentation of the corpora...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TVBoxOSC</td>\n",
       "      <td>真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。</td>\n",
       "      <td>11</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>angular</td>\n",
       "      <td>Deliver web apps with confidence 🚀</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Repository Name  \\\n",
       "0               multipleWindow3dScene   \n",
       "1                                rags   \n",
       "2                            roadster   \n",
       "3   Awesome-Black-Friday-Cyber-Monday   \n",
       "4                                live   \n",
       "5                      clash-nyanpasu   \n",
       "6                                GPTs   \n",
       "7                            hot-tips   \n",
       "8                             Fooocus   \n",
       "9                           app-ideas   \n",
       "10                          starrocks   \n",
       "11                             botlib   \n",
       "12          GitHub-Chinese-Top-Charts   \n",
       "13                             1Panel   \n",
       "14              chatgpt_system_prompt   \n",
       "15                  generative-models   \n",
       "16                    Reactive-Resume   \n",
       "17                   AI-For-Beginners   \n",
       "18                        awesome-cpp   \n",
       "19                 Black-Friday-Deals   \n",
       "20                        spring-boot   \n",
       "21                           windmill   \n",
       "22   Network-segmentation-cheat-sheet   \n",
       "23                           TVBoxOSC   \n",
       "24                            angular   \n",
       "\n",
       "                                          Description Contributors Count  \\\n",
       "0   A quick example of how one can \"synchronize\" a...                  2   \n",
       "1   Build ChatGPT over your data, all with natural...                  5   \n",
       "2   2008-2012 Roadster Development and Diagnostic ...                  -   \n",
       "3   Awesome deals on Black Friday: Apps, SaaS, Boo...                567   \n",
       "4   ✯ 一个可直连访问的电视/广播图标库与相关工具项目 ✯ 🔕 永久免费 直连访问 完整开源 不...                  -   \n",
       "5                                     Clash Nyanpasu!                 26   \n",
       "6                              leaked prompts of GPTs                  3   \n",
       "7                         The code behind my hot tips                  -   \n",
       "8                   Focus on prompting and generating                  -   \n",
       "9   A Collection of application ideas which can be...                 68   \n",
       "10  StarRocks, a Linux Foundation project, is a ne...                293   \n",
       "11                           C Telegram bot framework                  -   \n",
       "12  🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需...                  -   \n",
       "13                     🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。                 38   \n",
       "14                    store all agent's system prompt                  3   \n",
       "15                  Generative Models by Stability AI                 15   \n",
       "16  A one-of-a-kind resume builder that keeps your...                  -   \n",
       "17                  12 Weeks, 24 Lessons, AI for All!                 33   \n",
       "18  A curated list of awesome C++ (or C) framework...                381   \n",
       "19  Black Friday Deals for macOS / iOS Software & ...                259   \n",
       "20                                        Spring Boot              1,039   \n",
       "21  Open-source developer platform to turn scripts...                 57   \n",
       "22  Best practices for segmentation of the corpora...                  -   \n",
       "23          真的没有QQ群、QQ频道、论坛。打包分发注意开源协议，保留出处，不守规矩就不要搞。                 11   \n",
       "24                 Deliver web apps with confidence 🚀                  -   \n",
       "\n",
       "       Language Used  \n",
       "0         JavaScript  \n",
       "1             Python  \n",
       "2                  -  \n",
       "3                  -  \n",
       "4                  -  \n",
       "5         TypeScript  \n",
       "6                  -  \n",
       "7                  -  \n",
       "8                  -  \n",
       "9                  -  \n",
       "10              Java  \n",
       "11                 -  \n",
       "12                 -  \n",
       "13                Go  \n",
       "14             Shell  \n",
       "15            Python  \n",
       "16                 -  \n",
       "17  Jupyter Notebook  \n",
       "18                 -  \n",
       "19             Swift  \n",
       "20              Java  \n",
       "21        JavaScript  \n",
       "22                 -  \n",
       "23              Java  \n",
       "24                 -  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Clicking on Open source option\n",
    "WebDriverWait(driver,2).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\"))).click()\n",
    "\n",
    "# Clicking on Trending Repo\n",
    "WebDriverWait(driver,1).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\"))).click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Gathering the links\n",
    "repo_title=[]\n",
    "repo_description=[]\n",
    "contri_count=[]\n",
    "lang_used=[]\n",
    "repo_url=[]\n",
    "\n",
    "\n",
    "repo_url_tags=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in repo_url_tags:\n",
    "    repo_url.append(i.get_attribute('href'))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Looping to URLs to scrap the data    \n",
    "for i in repo_url:\n",
    "    driver.get(i)    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Repository Name\n",
    "    try:\n",
    "        repo_title_tags=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/div/div[1]/div[1]/div/strong/a')\n",
    "        repo_title.append(repo_title_tags.text)\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        repo_title.append('-')\n",
    "\n",
    "    # About section Repository \n",
    "    try:\n",
    "        repo_description_tag=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[1]/div/div/p')\n",
    "        repo_description.append(repo_description_tag.text)\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        repo_description.append('-')   \n",
    "\n",
    "    # Number of Contibuters\n",
    "    try:\n",
    "        contri_count_tag=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span')\n",
    "        contri_count.append(contri_count_tag.text)\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        contri_count.append('-')   \n",
    "\n",
    "    try:\n",
    "        lang_used_tag=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[6]/div/ul/li[1]/a/span[1]')\n",
    "        lang_used.append(lang_used_tag.text)\n",
    "    except:\n",
    "        lang_used.append('-')    \n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Dataframe\n",
    "df=pd.DataFrame({'Repository Name':repo_title,'Description':repo_description,'Contributors Count':contri_count,'Language Used':lang_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "following details: \\\n",
    "A) Song name \\\n",
    "B) Artist name \\\n",
    "C) Last week rank \\\n",
    "D) Peak rank \\\n",
    "E) Weeks on board \\\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # setting up the url\n",
    "    url='https://www.billboard.com/'\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Clicking on CHARTS\n",
    "    WebDriverWait(driver,5).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\"))).click()\n",
    "\n",
    "    # Clicking on View chart (Billboard Hot 100)\n",
    "    WebDriverWait(driver,5).until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a\"))).click()\n",
    "except :\n",
    "    driver.get('https://www.billboard.com/charts/hot-100/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks On Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is It Over Now? (Taylor's Version) [From The V...</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mi Ex Tenia Razon</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Different 'Round Here</td>\n",
       "      <td>Riley Green Featuring Luke Combs</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Better Than Ever</td>\n",
       "      <td>YoungBoy Never Broke Again &amp; Rod Wave</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Soak City (Do It)</td>\n",
       "      <td>310babii</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Song Name  \\\n",
       "0                                        Cruel Summer   \n",
       "1                                         Lovin On Me   \n",
       "2                                  Paint The Town Red   \n",
       "3                                              Snooze   \n",
       "4   Is It Over Now? (Taylor's Version) [From The V...   \n",
       "..                                                ...   \n",
       "95                                  Mi Ex Tenia Razon   \n",
       "96                              Different 'Round Here   \n",
       "97                        But I Got A Beer In My Hand   \n",
       "98                                   Better Than Ever   \n",
       "99                                  Soak City (Do It)   \n",
       "\n",
       "                                   Artist Last Week Rank Peak Position  \\\n",
       "0                            Taylor Swift              1             1   \n",
       "1                             Jack Harlow              -             2   \n",
       "2                                Doja Cat              2             1   \n",
       "3                                     SZA              4             2   \n",
       "4                            Taylor Swift              3             1   \n",
       "..                                    ...            ...           ...   \n",
       "95                                Karol G             91            22   \n",
       "96       Riley Green Featuring Luke Combs              -            97   \n",
       "97                             Luke Bryan             98            92   \n",
       "98  YoungBoy Never Broke Again & Rod Wave              -            99   \n",
       "99                               310babii              -           100   \n",
       "\n",
       "   Weeks On Chart  \n",
       "0              28  \n",
       "1               1  \n",
       "2              15  \n",
       "3              49  \n",
       "4               3  \n",
       "..            ...  \n",
       "95             13  \n",
       "96              1  \n",
       "97              5  \n",
       "98              1  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrapipng data\n",
    "song_name=[]\n",
    "artist_name=[]\n",
    "rank_last_week=[]\n",
    "peak_rank=[]\n",
    "weeks_onboard=[]\n",
    "\n",
    "song_tag=driver.find_elements(By.XPATH,\"//div[@class='o-chart-results-list-row-container']/ul/li[4]/ul/li/h3\")\n",
    "for i in song_tag:\n",
    "    song_name.append(i.text.strip())\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# scrapimg the row elements\n",
    "row_element=[]\n",
    "row_element_tag=driver.find_elements(By.XPATH,\"//div[@class='o-chart-results-list-row-container']/ul/li[4]/ul/li/span\")\n",
    "for i in row_element_tag:\n",
    "    row_element.append(i.text.strip())\n",
    "\n",
    "# Artist Name\n",
    "for i in row_element[0:400:4]:\n",
    "    artist_name.append(i)\n",
    "\n",
    "# Rank Last Week\n",
    "for i in row_element[1:400:4]:\n",
    "    rank_last_week.append(i)\n",
    "    \n",
    "# Peak Rank\n",
    "for i in row_element[2:400:4]:\n",
    "    peak_rank.append(i)\n",
    "        \n",
    "# Weeks on the chart\n",
    "for i in row_element[3:400:4]:\n",
    "    weeks_onboard.append(i)\n",
    "\n",
    "driver.close()\n",
    "            \n",
    "# Dataframe\n",
    "df=pd.DataFrame({\"Song Name\":song_name,'Artist':artist_name,'Last Week Rank':rank_last_week,'Peak Position':peak_rank,'Weeks On Chart':weeks_onboard})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels. \\\n",
    "A) Book name \\\n",
    "B) Author name \\\n",
    "C) Volumes sold \\\n",
    "D) Publisher \\\n",
    "E) Genre \\\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                              Title            Author  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)\n",
    "\n",
    "# All row elements\n",
    "row_element=[]\n",
    "row_element_tag=driver.find_elements(By.CLASS_NAME,\"left\")\n",
    "for i in row_element_tag:\n",
    "    row_element.append(i.text)\n",
    "\n",
    "driver.close()    \n",
    "\n",
    "# Extract first 5 elements from the list for column names\n",
    "column_names = row_element[:6]\n",
    "\n",
    "# creating arrays with 6 concecutive elements\n",
    "num_rows = len(row_element) // 6\n",
    "reshaped_array = np.array(row_element[:num_rows * 6]).reshape(-1, 6)\n",
    "\n",
    "# Dataframe\n",
    "df = pd.DataFrame(reshaped_array, columns=column_names)\n",
    "\n",
    "# Excluding the first row (Used as column name)\n",
    "df=df.iloc[1:,:]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Desired Dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details: \\\n",
    "A) Name \\\n",
    "B) Year span \\\n",
    "C) Genre \\\n",
    "D) Run time \\\n",
    "E) Ratings \\\n",
    "F) Votes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV SHOW</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2225932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1293041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1055974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>310060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>269173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>213107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>277845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TV SHOW    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "      Runtime Ratings    Votes  \n",
       "0   4,189 min     9.2  2225932  \n",
       "1      51 min     8.7  1293041  \n",
       "2      44 min     8.1  1055974  \n",
       "3      60 min     7.5   310060  \n",
       "4      43 min     7.6   269173  \n",
       "..        ...     ...      ...  \n",
       "95     42 min     7.5    53259  \n",
       "96     50 min     7.8    65350  \n",
       "97     42 min     8.1   213107  \n",
       "98     45 min       7    44366  \n",
       "99    572 min     8.6   277845  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Scraping the data\n",
    "series_name=[]\n",
    "year_span=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "rating=[]\n",
    "vote=[]\n",
    "\n",
    "\n",
    "# Series Name\n",
    "series_name_tag=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "for i in series_name_tag:\n",
    "    series_name.append(i.text)\n",
    "\n",
    "# Years Series Ran\n",
    "year_span_tag=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in year_span_tag:\n",
    "    year_span.append(i.text)   \n",
    "\n",
    "# Genre\n",
    "genre_tag=driver.find_elements(By.CLASS_NAME,\"genre\")    \n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "\n",
    "# Total runtime \n",
    "runtime_tag=driver.find_elements(By.CLASS_NAME,\"runtime\")\n",
    "for i in runtime_tag:\n",
    "    run_time.append(i.text)\n",
    "\n",
    "# Ratings\n",
    "rating_tag=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "for i in rating_tag:\n",
    "    rating.append(i.text)\n",
    "\n",
    "# Votes recieved \n",
    "vote_tag=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"][3]/span[2]')\n",
    "for i in vote_tag:\n",
    "    vote.append(i.get_attribute('data-value'))\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Dataframe\n",
    "df=pd.DataFrame({'TV SHOW':series_name,'Year Span':year_span,'Genre':genre,'Runtime':run_time,'Ratings':rating,'Votes':vote})    \n",
    "df \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "have to find the following details: \\\n",
    "A) Dataset name \\\n",
    "B) Data type \\\n",
    "C) Task \\\n",
    "D) Attribute type \\\n",
    "E) No of instances \n",
    "F) No of attribute \n",
    "G) Year \\\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Type of Data</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. Of Rows</th>\n",
       "      <th>No. of Columns</th>\n",
       "      <th>Year Uploaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>5/31/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>10/6/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>4/26/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45211</td>\n",
       "      <td>16</td>\n",
       "      <td>2/13/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>11/30/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>11/16/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649</td>\n",
       "      <td>-</td>\n",
       "      <td>11/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>7/10/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>5/18/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>7/6/1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699</td>\n",
       "      <td>9</td>\n",
       "      <td>7/14/1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>541909</td>\n",
       "      <td>6</td>\n",
       "      <td>11/5/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Predict students' dropout and academic success</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>4424</td>\n",
       "      <td>36</td>\n",
       "      <td>12/12/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>4601</td>\n",
       "      <td>57</td>\n",
       "      <td>6/30/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Glass Identification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>8/31/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>7200</td>\n",
       "      <td>5</td>\n",
       "      <td>12/31/1986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Dataset  \\\n",
       "0                                             Iris   \n",
       "1                                    Heart Disease   \n",
       "2                                            Adult   \n",
       "3                                             Wine   \n",
       "4             Breast Cancer Wisconsin (Diagnostic)   \n",
       "5                                         Diabetes   \n",
       "6                                 Dry Bean Dataset   \n",
       "7                                   Car Evaluation   \n",
       "8                                     Wine Quality   \n",
       "9                       Rice (Cammeo and Osmancik)   \n",
       "10                                        Mushroom   \n",
       "11                                  Bank Marketing   \n",
       "12                                         Abalone   \n",
       "13                                   Census Income   \n",
       "14                    Statlog (German Credit Data)   \n",
       "15                             Student Performance   \n",
       "16                                   Breast Cancer   \n",
       "17                                      Automobile   \n",
       "18                                        Auto MPG   \n",
       "19              Breast Cancer Wisconsin (Original)   \n",
       "20                                   Online Retail   \n",
       "21  Predict students' dropout and academic success   \n",
       "22                                        Spambase   \n",
       "23                            Glass Identification   \n",
       "24                                 Thyroid Disease   \n",
       "\n",
       "                             Type of Data                        Task  \\\n",
       "0                                 Tabular              Classification   \n",
       "1                            Multivariate              Classification   \n",
       "2                            Multivariate              Classification   \n",
       "3                                 Tabular              Classification   \n",
       "4                            Multivariate              Classification   \n",
       "5               Multivariate, Time-Series              Classification   \n",
       "6                            Multivariate              Classification   \n",
       "7                            Multivariate              Classification   \n",
       "8                            Multivariate  Classification, Regression   \n",
       "9                            Multivariate              Classification   \n",
       "10                           Multivariate              Classification   \n",
       "11                           Multivariate              Classification   \n",
       "12                                Tabular  Classification, Regression   \n",
       "13                           Multivariate              Classification   \n",
       "14                           Multivariate              Classification   \n",
       "15                           Multivariate  Classification, Regression   \n",
       "16                           Multivariate              Classification   \n",
       "17                           Multivariate                  Regression   \n",
       "18                           Multivariate                  Regression   \n",
       "19                           Multivariate              Classification   \n",
       "20  Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
       "21                                Tabular              Classification   \n",
       "22                           Multivariate              Classification   \n",
       "23                           Multivariate              Classification   \n",
       "24            Multivariate, Domain-Theory              Classification   \n",
       "\n",
       "                Attribute Type No. Of Rows No. of Columns Year Uploaded  \n",
       "0                         Real         150              4     6/30/1988  \n",
       "1   Categorical, Integer, Real         303             13     6/30/1988  \n",
       "2         Categorical, Integer       48842             14     4/30/1996  \n",
       "3                Integer, Real         178             13     6/30/1991  \n",
       "4                         Real         569             30    10/31/1995  \n",
       "5         Categorical, Integer           1             20           NaN  \n",
       "6                Integer, Real       13611             16     9/13/2020  \n",
       "7                  Categorical        1728              6     5/31/1997  \n",
       "8                         Real        4898             11     10/6/2009  \n",
       "9                         Real        3810              7     10/5/2019  \n",
       "10                 Categorical        8124             22     4/26/1987  \n",
       "11        Categorical, Integer       45211             16     2/13/2012  \n",
       "12  Categorical, Integer, Real        4177              8    11/30/1995  \n",
       "13        Categorical, Integer       48842             14     4/30/1996  \n",
       "14        Categorical, Integer        1000             20    11/16/1994  \n",
       "15                     Integer         649              -    11/26/2014  \n",
       "16                 Categorical         286              9     7/10/1988  \n",
       "17  Categorical, Integer, Real         205             25     5/18/1987  \n",
       "18  Real, Categorical, Integer         398              7      7/6/1993  \n",
       "19                     Integer         699              9     7/14/1992  \n",
       "20               Integer, Real      541909              6     11/5/2015  \n",
       "21                           -        4424             36    12/12/2021  \n",
       "22               Integer, Real        4601             57     6/30/1999  \n",
       "23                        Real         214              9     8/31/1987  \n",
       "24           Categorical, Real        7200              5    12/31/1986  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "# setting up the url\n",
    "url=\"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Clicking on View Datasets\n",
    "WebDriverWait(driver,2).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]'))).click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Selecting max listings (25) per page\n",
    "WebDriverWait(driver,2).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select/option[5]'))).click()\n",
    "\n",
    "# Scraping Urls\n",
    "data=[]\n",
    "data_type=[]\n",
    "task=[]\n",
    "att_type=[]\n",
    "no_of_instance=[]\n",
    "no_of_att=[]\n",
    "year=[]\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "dataset_url=[]\n",
    "url_tags=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "for i in url_tags:\n",
    "    dataset_url.append(i.get_attribute('href'))\n",
    "\n",
    "time.sleep(1)  \n",
    "\n",
    "# Scraping the data using urls\n",
    "for i in dataset_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Dataset Name\n",
    "    data_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/div/h1')\n",
    "    data.append(data_tag.text)\n",
    "\n",
    "    # Type of Dataset\n",
    "    data_type_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[1]/p')\n",
    "    data_type.append(data_type_tag.text)\n",
    "\n",
    "    # Task needed to be done\n",
    "    task_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "    task.append(task_tag.text)\n",
    "\n",
    "    # Feature Type\n",
    "    att_type_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "    att_type.append(att_type_tag.text)\n",
    "\n",
    "    # No of Instances\n",
    "    no_of_instance_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "    no_of_instance.append(no_of_instance_tag.text)\n",
    "\n",
    "    # No of Features\n",
    "    no_of_att_tag=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "    no_of_att.append(no_of_att_tag.text)\n",
    "\n",
    "    # Year the dataset was uploaded\n",
    "    try:\n",
    "        year_tag=driver.find_element(By.XPATH,\"//h2[@class='text-sm text-primary-content']\")\n",
    "        year.append(year_tag.text.replace(\"Donated on \",\"\"))\n",
    "    except:\n",
    "        year.append(np.nan)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Dataframe  \n",
    "df=pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\":data,\n",
    "        \"Type of Data\":data_type,\n",
    "        \"Task\":task,\n",
    "        \"Attribute Type\":att_type,\n",
    "        \"No. Of Rows\":no_of_instance,\n",
    "        \"No. of Columns\":no_of_att,\n",
    "        \"Year Uploaded\":year\n",
    "    }\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
